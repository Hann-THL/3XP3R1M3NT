{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataframe.to_gbq()\n",
    "### NOTE: Extremely slow dealing with big data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = 'PROJECT_ID'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Data\n",
    "df = pd.read_csv('resources/data/influxdb_sample.csv', delimiter='\\t',\n",
    "                 parse_dates=['time'],\n",
    "                 date_parser=lambda x: pd.to_datetime(x, format='%Y-%m-%dT%H:%M:%SZ'))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert data\n",
    "db = 'testdb'\n",
    "table = 'test_tbl'\n",
    "table_id = f'{db}.{table}'\n",
    "\n",
    "df.to_gbq(table_id, project_id=project_id, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select data\n",
    "sql = f'''\n",
    "SELECT *\n",
    "FROM `{table_id}`\n",
    "'''\n",
    "\n",
    "res_df = pd.read_gbq(sql, project_id=project_id, index_col='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# client.load_table_from_file()\n",
    "### NOTE: Faster dealing with big data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery as bq\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create service account key:\n",
    "# https://cloud.google.com/docs/authentication/production#auth-cloud-implicit-python\n",
    "\n",
    "path = 'resources/credential/Google_BigQuery_credential-xxx.json'\n",
    "client = bq.Client.from_service_account_json(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = 'gbq-trial-254606'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = 'testdb'\n",
    "table = 'test_tbl'\n",
    "table_id = f'{db}.{table}'\n",
    "\n",
    "# Drop table if exist\n",
    "client.delete_table(table_id, not_found_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ref = client.dataset(db)\n",
    "\n",
    "job_config = bq.LoadJobConfig()\n",
    "job_config.schema = [\n",
    "    bq.SchemaField(\"time\", \"TIMESTAMP\"), # NOTE: only canomical format is accepted\n",
    "    bq.SchemaField(\"butterflies\", \"INTEGER\"),\n",
    "    bq.SchemaField(\"honeybees\", \"INTEGER\"),\n",
    "    bq.SchemaField(\"location\", \"INTEGER\"),\n",
    "    bq.SchemaField(\"scientist\", \"STRING\"),\n",
    "]\n",
    "\n",
    "job_config.field_delimiter = '\\t'\n",
    "job_config.skip_leading_rows = 1 # 0 if no header\n",
    "job_config.source_format = bq.SourceFormat.CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = f'resources/data/influxdb_sample.csv'\n",
    "\n",
    "print(f'Reading: {file}')\n",
    "with open(file, 'rb') as source_file:\n",
    "    # Insert data\n",
    "    load_job = client.load_table_from_file(\n",
    "        source_file, dataset_ref.table(table), job_config=job_config\n",
    "    )\n",
    "    print(f'Job ID: {load_job.job_id}')\n",
    "    \n",
    "    load_job.result() # Waits for table load to complete.\n",
    "    print('Job Finished')\n",
    "    \n",
    "    destination_table = client.get_table(dataset_ref.table(table))\n",
    "    print(f'Loaded {destination_table.num_rows} rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select data\n",
    "sql = f'''\n",
    "SELECT *\n",
    "FROM `{table_id}`\n",
    "'''\n",
    "\n",
    "# Fastest, but result is not in dataframe\n",
    "# query_job = client.query(sql)\n",
    "# result = query_job.result()\n",
    "\n",
    "# Medium\n",
    "query_job = client.query(sql)\n",
    "res_df = query_job.to_dataframe()\n",
    "\n",
    "# Slowest\n",
    "# res_df = pd.read_gbq(sql, project_id=project_id, index_col='time', use_bqstorage_api=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST: Import Tick Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery as bq\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create service account key:\n",
    "# https://cloud.google.com/docs/authentication/production#auth-cloud-implicit-python\n",
    "\n",
    "path = 'resources/credential/Google_BigQuery_credential-xxx.json'\n",
    "client = bq.Client.from_service_account_json(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = 'PROJECT_ID'\n",
    "\n",
    "db = 'tickdb'\n",
    "db_id = f'{project_id}.{db}'\n",
    "\n",
    "table = 'tick_tbl'\n",
    "table_id = f'{db}.{table}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create db if not exist\n",
    "if db not in [x.dataset_id for x in list(client.list_datasets())]:\n",
    "    dataset = bq.Dataset(db_id)\n",
    "    client.create_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop table if exist\n",
    "client.delete_table(table_id, not_found_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ref = client.dataset(db)\n",
    "\n",
    "job_config = bq.LoadJobConfig()\n",
    "job_config.schema = [\n",
    "    bq.SchemaField(\"datetime\", \"TIMESTAMP\"),\n",
    "    bq.SchemaField(\"bid\", \"FLOAT\"),\n",
    "    bq.SchemaField(\"ask\", \"FLOAT\"),\n",
    "    bq.SchemaField(\"currency_pair\", \"STRING\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "periods = [f'2019{x+1:02}' for x in range(3)]\n",
    "chunk_size = 10000\n",
    "\n",
    "for period in periods:\n",
    "    currency_pair = 'AUDUSD'\n",
    "    file = f'resources/data/DAT_ASCII_{currency_pair}_T_{period}.csv'\n",
    "    print(f'Reading: {file}')\n",
    "    \n",
    "    # Transform timestamp to format expected by GBQ\n",
    "    df_chunks = pd.read_csv(file, sep=',',\n",
    "                            header=None, names=['datetime', 'bid', 'ask', 'vol'],\n",
    "                            usecols=['datetime', 'bid', 'ask'],\n",
    "                            parse_dates=[\"datetime\"],\n",
    "                            date_parser=lambda x: pd.to_datetime(x, format=\"%Y%m%d %H%M%S%f\"),\n",
    "                            chunksize=chunk_size)\n",
    "    \n",
    "    # Merge df together instead of uploading by batch, as batch insert is much slower\n",
    "    full_df = pd.concat(df_chunks)\n",
    "    full_df['currency_pair'] = currency_pair\n",
    "    \n",
    "    # Insert to GBQ\n",
    "    load_job = client.load_table_from_dataframe(full_df, dataset_ref.table(table), job_config=job_config)\n",
    "    print(f'Job ID: {load_job.job_id}')\n",
    "    \n",
    "    load_job.result() # Waits for table load to complete.\n",
    "    print('Job Finished')\n",
    "    \n",
    "    destination_table = client.get_table(dataset_ref.table(table))\n",
    "    print(f'Loaded {destination_table.num_rows} rows\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXEC_START = time.time()\n",
    "\n",
    "# Select data\n",
    "sql = f'''\n",
    "SELECT *\n",
    "FROM `{table_id}`\n",
    "'''\n",
    "\n",
    "query_job = client.query(sql)\n",
    "res_df = query_job.to_dataframe()\n",
    "\n",
    "EXEC_END = time.time()\n",
    "print(f'\\n{EXEC_END - EXEC_START} sec.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
