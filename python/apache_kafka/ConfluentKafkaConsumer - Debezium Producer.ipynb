{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Install Confluent Apache Kafka?\n",
    "- https://nijanthanravi.wordpress.com/2019/07/14/setup-confluent-kafka-on-windows/\n",
    "- https://medium.com/@praveenkumarsingh/confluent-kafka-on-windows-how-to-fix-classpath-is-empty-cf7c31d9c787\n",
    "\n",
    "### Python Dependencies:\n",
    "- pip install confluent-kafka\n",
    "- pip install avro-python3\n",
    "\n",
    "### MySQL Script:\n",
    "```\n",
    "CREATE TABLE `testdb`.`products` (\n",
    "  `product_id` INT NOT NULL AUTO_INCREMENT,\n",
    "  `name` VARCHAR(45) NOT NULL,\n",
    "  `price` DECIMAL(6,2) NULL,\n",
    "  `expiration_date` DATE NULL,\n",
    "  PRIMARY KEY (`product_id`)\n",
    ");\n",
    "\n",
    "INSERT INTO testdb.products (name, price, expiration_date)\n",
    "VALUES ('product name 1', 5.5, '2019-02-10');\n",
    "\n",
    "UPDATE testdb.products SET price=0;\n",
    "\n",
    "DELETE FROM testdb.products;\n",
    "```\n",
    "\n",
    "### How to Start Confluent Apache Kafka?\n",
    "1. Open command prompt at confluent folder\n",
    "\n",
    "\n",
    "2. Start Zookeeper<br>\n",
    "   2.1 Execute ***bin\\windows\\zookeeper-server-start.bat etc\\kafka\\zookeeper.properties***<br>\n",
    "   2.2 Default port is ```2181```, change at ***etc\\kafka\\zookeeper.properties*** if necessary<br>\n",
    "   2.3 If encounter ```Classpath``` error:\n",
    "   - Open ***bin\\windows\\kafka-run-class.bat***\n",
    "   - Search for ```rem Classpath addition for core``` in the bat file\n",
    "   - Add following lines above the search line:\n",
    "   ```\n",
    "   rem classpath addition for LSB style path\n",
    "   if exist %BASE_DIR%\\share\\java\\kafka\\* (\n",
    "     call:concat %BASE_DIR%\\share\\java\\kafka\\*\n",
    "   )\n",
    "   ```\n",
    "   - Re-run zookeeper\n",
    "\n",
    "\n",
    "3. Start Kafka Broker<br>\n",
    "   3.1 Execute ***bin\\windows\\kafka-server-start.bat etc\\kafka\\server.properties***<br>\n",
    "   3.2 Delete ***tmp\\kafka-log*** & ***tmp\\zookeeper*** folder if encounter ```ERROR Shutdown broker because all log dirs in tmp\\kafka-logs have failed (kafka.log.LogManager)```\n",
    "\n",
    "\n",
    "4. Debezium MySQL CDC Connector<br>\n",
    "   4.1 Download:\n",
    "   - https://www.confluent.io/hub/debezium/debezium-connector-mysql\n",
    "   4.2 Create ***share\\java\\kafka\\plugins*** folder, and move downloaded jar files to the folder\n",
    "   - Ensure to check if there's latest debezium plugin version from official debezium website\n",
    "   4.3 Ensure ```plugin.path``` is set as ```plugin.path=share/java``` on ***etc\\kafka\\connect-distributed.properties*** file\n",
    "   4.4 Configure MySQL binlog:\n",
    "   - Reference:\n",
    "     - https://documentation.commvault.com/commvault/v11/article?p=34667.htm\n",
    "     - https://debezium.io/documentation/reference/0.9/connectors/mysql.html\n",
    "   - Comment out default ```log-bin``` value from ***my.ini*** file, and paste the following:\n",
    "   ```\n",
    "    log_bin=mysql-bin\n",
    "    binlog_format=row\n",
    "    binlog_row_image=full\n",
    "    expire_logs_days=1\n",
    "    gtid_mode=on\n",
    "    enforce_gtid_consistency=on\n",
    "    binlog_rows_query_log_events=on\n",
    "   ```\n",
    "   - Check MySQL variables:\n",
    "   ```\n",
    "   SHOW VARIABLES WHERE variable_name IN ('server_id','log_bin','binlog_format','binlog_row_image', 'expire_logs_days');\n",
    "   SHOW VARIABLES WHERE variable_name IN ('gtid_mode', 'enforce_gtid_consistency', 'binlog_rows_query_log_events');\n",
    "   ```\n",
    "\n",
    "\n",
    "5. Start Connector<br>\n",
    "   5.1 Execute ***bin\\windows\\connect-distributed.bat etc\\kafka\\connect-distributed.properties***<br>\n",
    "   5.2 If encounter ```FileNotFoundException```:\n",
    "   - Open ***bin\\windows\\connect-distributed.bat***\n",
    "   - Search for ```rem Log4j settings``` in the bat file\n",
    "   - Replace ```config/tools-log4j.properties``` with ```etc/kafka/tools-log4j.properties```\n",
    "   - Re-run connector\n",
    "   5.3 Check if http://localhost:8083/ is running\n",
    "\n",
    "\n",
    "6. Start Debezium Source Connector (Producer)<br>\n",
    "   6.1 Run following on bash prompt, or perform POST request on Postman:\n",
    "   ```\n",
    "    curl -X POST -H \"Content-Type: application/json\" http://localhost:8083/connectors -d '{\n",
    "        \"name\": \"debezium-mysql-source-connector\",\n",
    "        \"config\": {\n",
    "            \"connector.class\": \"io.debezium.connector.mysql.MySqlConnector\",\n",
    "            \"tasks.max\": 1,\n",
    "            \"database.hostname\": \"localhost\",\n",
    "            \"database.port\": \"3306\",\n",
    "            \"database.user\": \"root\",\n",
    "            \"database.password\": \"root\",\n",
    "            \"database.server.id\": \"184054\",\n",
    "            \"database.server.name\": \"test_server\",\n",
    "            \"database.whitelist\": \"testdb\",\n",
    "            \"table.whitelist\": \"testdb.products\",\n",
    "            \"database.history.kafka.bootstrap.servers\": \"localhost:9092\",\n",
    "            \"database.history.kafka.topic\": \"TEST_TOPIC\",\n",
    "            \"snapshot.mode\": \"schema_only\"\n",
    "        }\n",
    "    }'\n",
    "   ```\n",
    "   6.2 If encounter unrecognized server timezone error:\n",
    "   - Download SQL script (POSIX standard) to populate timezone data at: https://dev.mysql.com/downloads/timezones.html\n",
    "   - Add ```USE mysql;``` at the beginning of script, and run it to populate timezone data\n",
    "   - Change timezone once complete: ```SET GLOBAL time_zone='Asia/Kuala_Lumpur'```\n",
    "   - Re-submit POST request\n",
    "   6.3 Ensure connector & tasks are in \"RUNNING\" state:\n",
    "   - http://localhost:8083/connectors/debezium-mysql-source-connector/status\n",
    "\n",
    "\n",
    "7. List topic (Optional)<br>\n",
    "   7.1 Execute ***bin\\windows\\kafka-topics.bat --list --bootstrap-server localhost:9092***<br>\n",
    "   7.2 <font color='red'>**NOTE**</font>: Topic naming convention to listen on will be: ```<serverName>.<databaseName>.<tableName>```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaConsumer\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer = KafkaConsumer(bootstrap_servers=['localhost:9092'], auto_offset_reset='earliest')\n",
    "consumer.topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "consumer.subscribe(['test_server.testdb.products'])\n",
    "for message in consumer:\n",
    "    \n",
    "    value = json.loads('{}' if message.value is None else message.value)\n",
    "    value = {k: v for k,v in value.get('payload', {}).items() if k in ['before', 'after', 'op']}\n",
    "    \n",
    "    print(f'[CONSUMED]:')\n",
    "    print(json.dumps(value, indent=2))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
